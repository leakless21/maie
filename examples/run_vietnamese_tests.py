#!/usr/bin/env python3
"""
V√≠ d·ª• v·ªÅ c√°ch ch·∫°y c√°c b√†i ki·ªÉm tra LLM th·ª±c v·ªõi vƒÉn b·∫£n ti·∫øng Vi·ªát.

Script n√†y minh h·ªça c√°ch thi·∫øt l·∫≠p v√† ch·∫°y c√°c b√†i ki·ªÉm tra t√≠ch h·ª£p LLM
v·ªõi d·ªØ li·ªáu ti·∫øng Vi·ªát th·ª±c t·∫ø.
"""

import os
import subprocess
import sys
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.config import settings


def check_pixi_availability():
    """Ki·ªÉm tra xem pixi c√≥ s·∫µn s√†ng kh√¥ng."""
    try:
        result = subprocess.run(
            ["pixi", "--version"], capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            version = result.stdout.strip()
            print(f"‚úÖ Pixi version: {version}")
            return True
        else:
            print("‚ùå Pixi kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng c√°ch")
            return False
    except FileNotFoundError:
        print("‚ùå Pixi kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        return False
    except subprocess.TimeoutExpired:
        print("‚ùå Pixi kh√¥ng ph·∫£n h·ªìi")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói khi ki·ªÉm tra Pixi: {e}")
        return False


def sync_dependencies():
    """C√†i ƒë·∫∑t dependencies v·ªõi Pixi."""
    print("üîÑ ƒê·ªìng b·ªô dependencies...")
    try:
        result = subprocess.run(
            ["pixi", "install"], cwd=Path(__file__).parent.parent, timeout=120
        )
        if result.returncode == 0:
            print("‚úÖ Dependencies ƒë√£ ƒë∆∞·ª£c ƒë·ªìng b·ªô th√†nh c√¥ng")
            return True
        else:
            print("‚ùå L·ªói khi ƒë·ªìng b·ªô dependencies")
            return False
    except subprocess.TimeoutExpired:
        print("‚ùå Timeout khi ƒë·ªìng b·ªô dependencies")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªìng b·ªô dependencies: {e}")
        return False


def check_dependencies():
    """Ki·ªÉm tra c√°c dependencies c·∫ßn thi·∫øt."""
    print("üîç Ki·ªÉm tra dependencies...")

    # Ki·ªÉm tra pixi
    if not check_pixi_availability():
        print("\n‚ùå C·∫ßn c√†i ƒë·∫∑t Pixi:")
        print("   curl -fsSL https://pixi.sh/install.sh | bash")
        return False

    # Ki·ªÉm tra pytest trong pixi environment
    try:
        result = subprocess.run(
            ["pixi", "run", "python", "-c", "import pytest; print('pytest available')"],
            capture_output=True,
            text=True,
            timeout=30,
        )
        if result.returncode == 0:
            print("‚úÖ pytest c√≥ s·∫µn trong Pixi environment")
            return True
        else:
            print("‚ùå pytest kh√¥ng c√≥ s·∫µn trong Pixi environment")
            print("üîÑ Th·ª≠ ƒë·ªìng b·ªô dependencies...")
            if sync_dependencies():
                # Ki·ªÉm tra l·∫°i sau khi sync
                result = subprocess.run(
                    [
                        "pixi",
                        "run",
                        "python",
                        "-c",
                        "import pytest; print('pytest available')",
                    ],
                    capture_output=True,
                    text=True,
                    timeout=30,
                )
                if result.returncode == 0:
                    print("‚úÖ pytest ƒë√£ c√≥ s·∫µn sau khi ƒë·ªìng b·ªô")
                    return True
            print("   Ch·∫°y th·ªß c√¥ng: pixi install")
            return False
    except Exception as e:
        print(f"‚ùå L·ªói khi ki·ªÉm tra pytest: {e}")
        return False


def show_help():
    """Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng script."""
    print(
        """
üöÄ Vietnamese LLM Testing Script

C√°ch s·ª≠ d·ª•ng:
    # S·ª≠ d·ª•ng Pixi (khuy·∫øn ngh·ªã)
    pixi run python examples/run_vietnamese_tests.py
    
    # Ho·∫∑c s·ª≠ d·ª•ng Python tr·ª±c ti·∫øp
    python examples/run_vietnamese_tests.py

Y√™u c·∫ßu:
    - Pixi package manager (https://pixi.sh)
    - Dependencies ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t: pixi install

C·∫•u h√¨nh:
    Script n√†y s·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ src/config.py v√† environment variables.

    Environment Variables (t√πy ch·ªçn):
    - LLM_TEST_MODEL_PATH: ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh LLM c·ª•c b·ªô
    - LLM_TEST_API_KEY: API key cho d·ªãch v·ª• LLM ƒë√°m m√¢y
    - LLM_TEST_TEMPERATURE: Nhi·ªát ƒë·ªô cho generation (m·∫∑c ƒë·ªãnh t·ª´ config)
    - LLM_TEST_MAX_TOKENS: S·ªë token t·ªëi ƒëa (m·∫∑c ƒë·ªãnh t·ª´ config)
    - LLM_TEST_TIMEOUT: Th·ªùi gian ch·ªù (m·∫∑c ƒë·ªãnh: 60s)

    C·∫•u h√¨nh t·ª´ config.py:
    - llm_enhance_model: M√¥ h√¨nh cho text enhancement
    - llm_sum_model: M√¥ h√¨nh cho summarization
    - llm_enhance_temperature: Nhi·ªát ƒë·ªô cho enhancement
    - llm_sum_temperature: Nhi·ªát ƒë·ªô cho summarization
    - llm_enhance_max_tokens: Token t·ªëi ƒëa cho enhancement
    - llm_sum_max_tokens: Token t·ªëi ƒëa cho summarization

V√≠ d·ª•:
    # S·ª≠ d·ª•ng c·∫•u h√¨nh m·∫∑c ƒë·ªãnh t·ª´ config.py
    pixi run python examples/run_vietnamese_tests.py

    # S·ª≠ d·ª•ng model path t√πy ch·ªânh
    LLM_TEST_MODEL_PATH=/path/to/model pixi run python examples/run_vietnamese_tests.py

    # S·ª≠ d·ª•ng API key
    LLM_TEST_API_KEY=sk-123... pixi run python examples/run_vietnamese_tests.py

C√†i ƒë·∫∑t Pixi:
    curl -fsSL https://pixi.sh/install.sh | bash

C√†i ƒë·∫∑t dependencies:
    pixi install
"""
    )


def validate_configuration():
    """Ki·ªÉm tra v√† x√°c th·ª±c c·∫•u h√¨nh cho c√°c b√†i ki·ªÉm tra."""
    issues = []
    warnings = []

    # Ki·ªÉm tra enhancement model path
    enhance_model_path = os.getenv("LLM_TEST_MODEL_PATH") or settings.llm_enhance_model
    if enhance_model_path:
        if not Path(enhance_model_path).exists():
            issues.append(f"Enhancement model path kh√¥ng t·ªìn t·∫°i: {enhance_model_path}")
        else:
            print(f"‚úÖ Enhancement model path h·ª£p l·ªá: {enhance_model_path}")
    else:
        issues.append("Kh√¥ng c√≥ enhancement model path ƒë∆∞·ª£c c·∫•u h√¨nh")

    # Ki·ªÉm tra summarization model path
    sum_model_path = settings.llm_sum_model
    if sum_model_path:
        # Ki·ªÉm tra xem c√≥ ph·∫£i l√† HuggingFace model ID kh√¥ng (ch·ª©a "/")
        if "/" in sum_model_path and not Path(sum_model_path).exists():
            print(f"‚úÖ Summarization model (HuggingFace): {sum_model_path}")
        elif Path(sum_model_path).exists():
            print(f"‚úÖ Summarization model path h·ª£p l·ªá: {sum_model_path}")
        else:
            warnings.append(f"Summarization model path kh√¥ng t·ªìn t·∫°i: {sum_model_path}")

    # Ki·ªÉm tra API key
    api_key = os.getenv("LLM_TEST_API_KEY")
    if not enhance_model_path and not api_key:
        issues.append("C·∫ßn c·∫•u h√¨nh model path ho·∫∑c API key")

    # Ki·ªÉm tra templates directory
    if not settings.templates_dir.exists():
        warnings.append(f"Templates directory kh√¥ng t·ªìn t·∫°i: {settings.templates_dir}")

    # Ki·ªÉm tra models directory
    if not settings.models_dir.exists():
        warnings.append(f"Models directory kh√¥ng t·ªìn t·∫°i: {settings.models_dir}")

    # Ki·ªÉm tra c·∫•u h√¨nh LLM parameters
    if settings.llm_enhance_temperature < 0 or settings.llm_enhance_temperature > 2:
        warnings.append(
            f"LLM enhancement temperature ngo√†i ph·∫°m vi h·ª£p l·ªá: {settings.llm_enhance_temperature}"
        )

    if settings.llm_sum_temperature < 0 or settings.llm_sum_temperature > 2:
        warnings.append(
            f"LLM summarization temperature ngo√†i ph·∫°m vi h·ª£p l·ªá: {settings.llm_sum_temperature}"
        )

    return issues, warnings


def main():
    """Ch·∫°y c√°c b√†i ki·ªÉm tra LLM th·ª±c v·ªõi c·∫•u h√¨nh ti·∫øng Vi·ªát."""

    # Ki·ªÉm tra argument help
    if len(sys.argv) > 1 and sys.argv[1] in ["-h", "--help", "help"]:
        show_help()
        return 0

    print("üöÄ Ch·∫°y c√°c b√†i ki·ªÉm tra LLM th·ª±c v·ªõi vƒÉn b·∫£n ti·∫øng Vi·ªát")
    print("=" * 60)

    # Ki·ªÉm tra dependencies tr∆∞·ªõc
    if not check_dependencies():
        print("\n‚ùå Dependencies kh√¥ng ƒë·∫ßy ƒë·ªß. Vui l√≤ng c√†i ƒë·∫∑t tr∆∞·ªõc khi ch·∫°y.")
        return 1

    # X√°c th·ª±c c·∫•u h√¨nh
    print("\nüîç Ki·ªÉm tra c·∫•u h√¨nh...")
    issues, warnings = validate_configuration()

    # Hi·ªÉn th·ªã warnings
    if warnings:
        print("\n‚ö†Ô∏è  C·∫£nh b√°o:")
        for warning in warnings:
            print(f"   - {warning}")

    # Ki·ªÉm tra issues
    if issues:
        print("\n‚ùå L·ªói c·∫•u h√¨nh:")
        for issue in issues:
            print(f"   - {issue}")
        print("\nC√°c c√°ch c·∫•u h√¨nh:")
        print("  1. ƒê·∫∑t LLM_TEST_MODEL_PATH environment variable")
        print("  2. ƒê·∫∑t LLM_TEST_API_KEY environment variable")
        print("  3. C·∫•u h√¨nh llm_enhance_model trong config.py")
        print("\nV√≠ d·ª•:")
        print("  export LLM_TEST_MODEL_PATH='/path/to/your/model'")
        print("  # HO·∫∂C")
        print("  export LLM_TEST_API_KEY='sk-your-api-key-here'")
        print("\nSau ƒë√≥ ch·∫°y l·∫°i script n√†y.")
        return 1

    # L·∫•y c·∫•u h√¨nh ƒë√£ x√°c th·ª±c
    model_path = os.getenv("LLM_TEST_MODEL_PATH") or settings.llm_enhance_model
    api_key = os.getenv("LLM_TEST_API_KEY")

    # Hi·ªÉn th·ªã c·∫•u h√¨nh
    print(f"\nüìã Th√¥ng tin c·∫•u h√¨nh:")
    if model_path:
        print(f"   üìÅ M√¥ h√¨nh c·ª•c b·ªô: {model_path}")
        if Path(model_path).exists():
            print(f"   ‚úÖ ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh h·ª£p l·ªá")
        else:
            print(f"   ‚ö†Ô∏è  ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh kh√¥ng t·ªìn t·∫°i")
    if api_key:
        print(f"   üîë API key: {api_key[:10]}...")

    # Hi·ªÉn th·ªã c·∫•u h√¨nh t·ª´ settings
    print(f"   üèóÔ∏è  C·∫•u h√¨nh t·ª´ config.py:")
    print(f"      - Environment: {settings.environment}")
    print(f"      - Debug mode: {settings.debug}")
    print(f"      - Templates dir: {settings.templates_dir}")
    print(f"      - Models dir: {settings.models_dir}")

    # C·∫•u h√¨nh m√¥i tr∆∞·ªùng cho ti·∫øng Vi·ªát
    # S·ª≠ d·ª•ng c·∫•u h√¨nh t·ª´ settings, v·ªõi fallback cho test-specific values
    env = os.environ.copy()
    env.update(
        {
            "LLM_TEST_MODEL_PATH": model_path or "",
            "LLM_TEST_API_KEY": api_key or "",
            "LLM_TEST_TEMPERATURE": str(
                os.getenv("LLM_TEST_TEMPERATURE", settings.llm_enhance_temperature)
            ),
            "LLM_TEST_MAX_TOKENS": str(
                os.getenv("LLM_TEST_MAX_TOKENS", settings.llm_enhance_max_tokens or 200)
            ),
            "LLM_TEST_TIMEOUT": str(os.getenv("LLM_TEST_TIMEOUT", "60")),
            "PYTHONPATH": str(Path(__file__).parent.parent),
            # Th√™m c·∫•u h√¨nh cho summarization model
            "LLM_SUM_MODEL": settings.llm_sum_model,
            "LLM_SUM_TEMPERATURE": str(settings.llm_sum_temperature),
            "LLM_SUM_MAX_TOKENS": str(settings.llm_sum_max_tokens or 1000),
            "LLM_SUM_QUANTIZATION": str(settings.llm_sum_quantization or ""),
            # Th√™m c·∫•u h√¨nh quantization cho enhancement model
            "LLM_ENHANCE_QUANTIZATION": str(settings.llm_enhance_quantization or ""),
        }
    )

    print(f"\n‚öôÔ∏è  C·∫•u h√¨nh LLM:")
    print(f"   - M√¥ h√¨nh enhancement: {model_path}")
    print(f"   - M√¥ h√¨nh summarization: {settings.llm_sum_model}")
    print(f"   - Nhi·ªát ƒë·ªô enhancement: {env['LLM_TEST_TEMPERATURE']}")
    print(f"   - Nhi·ªát ƒë·ªô summarization: {env['LLM_SUM_TEMPERATURE']}")
    print(f"   - Token t·ªëi ƒëa enhancement: {env['LLM_TEST_MAX_TOKENS']}")
    print(f"   - Token t·ªëi ƒëa summarization: {env['LLM_SUM_MAX_TOKENS']}")
    print(f"   - Th·ªùi gian ch·ªù: {env['LLM_TEST_TIMEOUT']}s")
    print(f"   - GPU memory utilization: {settings.llm_enhance_gpu_memory_utilization}")
    print(f"   - Max model length enhancement: {settings.llm_enhance_max_model_len}")
    print(f"   - Max model length summarization: {settings.llm_sum_max_model_len}")
    print(
        f"   - Quantization enhancement: {settings.llm_enhance_quantization or 'auto-detect'}"
    )
    print(
        f"   - Quantization summarization: {settings.llm_sum_quantization or 'auto-detect'}"
    )

    # Ch·∫°y c√°c b√†i ki·ªÉm tra
    print(f"\nüß™ Ch·∫°y c√°c b√†i ki·ªÉm tra LLM th·ª±c...")

    cmd = [
        "pixi",
        "run",
        "pytest",
        "-m",
        "real_llm",
        "-v",
        "--tb=short",
        "tests/integration/test_real_llm_integration.py",
    ]

    try:
        result = subprocess.run(cmd, env=env, cwd=Path(__file__).parent.parent)

        if result.returncode == 0:
            print("\n‚úÖ T·∫•t c·∫£ c√°c b√†i ki·ªÉm tra ƒë√£ ho√†n th√†nh th√†nh c√¥ng!")
            print("\nüìä K·∫øt qu·∫£ ki·ªÉm tra bao g·ªìm:")
            print("   - C·∫£i thi·ªán vƒÉn b·∫£n ti·∫øng Vi·ªát")
            print("   - T√≥m t·∫Øt cu·ªôc h·ªçp c√≥ c·∫•u tr√∫c")
            print("   - T·∫£i v√† cache m√¥ h√¨nh")
            print("   - X·ª≠ l√Ω l·ªói")
            print("   - ƒê√°nh gi√° hi·ªáu su·∫•t")
        else:
            print(f"\n‚ùå M·ªôt s·ªë b√†i ki·ªÉm tra ƒë√£ th·∫•t b·∫°i (m√£ l·ªói: {result.returncode})")
            return result.returncode

    except FileNotFoundError:
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y pytest ho·∫∑c pixi.")
        print("   H√£y c√†i ƒë·∫∑t dependencies v·ªõi:")
        print("   pixi install")
        return 1
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        return 1
    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng mong mu·ªën: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
