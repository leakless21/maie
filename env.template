# ============================================================================
# MAIE (Modular Audio Intelligence Engine) - Configuration Template
# ============================================================================
# Copy this file to .env and fill in your values
# Version: 1.0.0

# ============================================================================
# Core Settings
# ============================================================================
PIPELINE_VERSION=1.0.0
ENVIRONMENT=development
DEBUG=false

# Component Verbose Output
# Show native output from components (FFmpeg, Whisper, vLLM)
# Enabled in development, disabled in production
VERBOSE_COMPONENTS=false

# ============================================================================
# API Server Settings
# ============================================================================
API_HOST=0.0.0.0
API_PORT=8000
SECRET_API_KEY=CHANGE_ME_TO_A_SECURE_KEY
MAX_FILE_SIZE_MB=500

# ============================================================================
# Redis Settings
# ============================================================================
REDIS_URL=redis://localhost:6379/0
REDIS_RESULTS_DB=1
MAX_QUEUE_DEPTH=50

# ============================================================================
# ASR Settings - Whisper (Default Backend)
# ============================================================================
# Model Configuration
WHISPER_MODEL_PATH=data/models/era-x-wow-turbo-v1.1-ct2
WHISPER_MODEL_VARIANT=erax-wow-turbo
# Options: erax-wow-turbo, large-v3, turbo, distil-large-v3

# Decoding Parameters
WHISPER_BEAM_SIZE=5
WHISPER_VAD_FILTER=true
WHISPER_VAD_MIN_SILENCE_MS=500
WHISPER_VAD_SPEECH_PAD_MS=400
WHISPER_DEVICE=cuda
# Options: cuda, cpu, auto

WHISPER_COMPUTE_TYPE=float16
# Options: float16, int8, int8_float16

WHISPER_CPU_FALLBACK=false
WHISPER_CONDITION_ON_PREVIOUS_TEXT=true
# Note: Set to false for Distil-Whisper models

# Language Settings
WHISPER_LANGUAGE=auto
# Set explicitly to skip auto-detection (recommended for offline deployment and tests)
# Options: en, vi, etc. or leave empty for auto-detection (may cause issues in multi-threaded contexts)

WHISPER_CPU_THREADS=
# Leave empty for auto, or set to number of threads (e.g., 4)

# ============================================================================
# ASR Settings - ChunkFormer (Long-form Backend)
# ============================================================================
# Model Configuration
CHUNKFORMER_MODEL_PATH=data/models/chunkformer-rnnt-large-vie
CHUNKFORMER_MODEL_VARIANT=khanhld/chunkformer-rnnt-large-vie

# ChunkFormer Decoding Parameters (CORRECTED VALUES - V1.0)
CHUNKFORMER_CHUNK_SIZE=64
# Chunk size in FRAMES (not samples) - Default: 64

CHUNKFORMER_LEFT_CONTEXT_SIZE=128
# Left context window size in FRAMES - Default: 128

CHUNKFORMER_RIGHT_CONTEXT_SIZE=128
# Right context window size in FRAMES - Default: 128

CHUNKFORMER_TOTAL_BATCH_DURATION=14400
# Total batch duration in SECONDS (not ms) - Default: 14400 (4 hours)

CHUNKFORMER_RETURN_TIMESTAMPS=true
# Whether to return timestamps - Default: true

# Device Settings
CHUNKFORMER_DEVICE=cuda
# Options: cuda, cpu, auto

CHUNKFORMER_BATCH_SIZE=
# Leave empty for sequential/unbatched, or set batch size

CHUNKFORMER_CPU_FALLBACK=false

# ============================================================================
# LLM Settings - Text Enhancement
# ============================================================================
LLM_ENHANCE_MODEL=cpatonn/Qwen3-4B-Instruct-2507-AWQ-4bit
LLM_ENHANCE_GPU_MEMORY_UTILIZATION=0.95
LLM_ENHANCE_MAX_MODEL_LEN=32768
LLM_ENHANCE_TEMPERATURE=0.0
LLM_ENHANCE_TOP_P=0.9
LLM_ENHANCE_TOP_K=20
LLM_ENHANCE_MAX_TOKENS=4096
LLM_ENHANCE_MAX_NUM_SEQS=
LLM_ENHANCE_MAX_NUM_BATCHED_TOKENS=
LLM_ENHANCE_MAX_NUM_PARTIAL_PREFILLS=

# ============================================================================
# LLM Settings - Summarization
# ============================================================================
LLM_SUM_MODEL=cpatonn/Qwen3-4B-Instruct-2507-AWQ-4bit
LLM_SUM_GPU_MEMORY_UTILIZATION=0.95
LLM_SUM_MAX_MODEL_LEN=32768
LLM_SUM_TEMPERATURE=0.7
LLM_SUM_TOP_P=0.9
LLM_SUM_TOP_K=20
LLM_SUM_MAX_TOKENS=4096
LLM_SUM_MAX_NUM_SEQS=
LLM_SUM_MAX_NUM_BATCHED_TOKENS=
LLM_SUM_MAX_NUM_PARTIAL_PREFILLS=

# ============================================================================
# File Paths
# ============================================================================
AUDIO_DIR=data/audio
MODELS_DIR=data/models
TEMPLATES_DIR=templates

# ============================================================================
# Worker Settings
# ============================================================================
WORKER_NAME=maie-worker
JOB_TIMEOUT=600
RESULT_TTL=86400

# ============================================================================
# Cleanup & Maintenance Settings (RQ Scheduler)
# ============================================================================
# Cleanup intervals (in seconds)
SCHEDULE_AUDIO_CLEANUP=3600       # Audio cleanup frequency (default: 1 hour)
SCHEDULE_LOG_CLEANUP=86400        # Log cleanup frequency (default: 24 hours)
SCHEDULE_CACHE_CLEANUP=1800       # Cache cleanup frequency (default: 30 minutes)
SCHEDULE_DISK_MONITOR=300         # Disk monitoring frequency (default: 5 minutes)

# Retention periods (in days)
CLEANUP_AUDIO_RETENTION_DAYS=7    # Keep audio files for 7 days
CLEANUP_LOGS_RETENTION_DAYS=7     # Keep log files for 7 days

# Disk monitoring
CLEANUP_DISK_THRESHOLD_PCT=80     # Alert when disk usage > 80%
CLEANUP_EMERGENCY_CLEANUP=false   # Enable automatic emergency cleanup on disk alerts
CLEANUP_CHECK_DIR=.               # Directory to monitor for disk usage

# ============================================================================
# Cleanup Configuration Notes
# ============================================================================
# Development Profile (faster cleanup for testing):
#   SCHEDULE_AUDIO_CLEANUP=60       # 1 minute
#   SCHEDULE_LOG_CLEANUP=3600       # 1 hour
#   SCHEDULE_CACHE_CLEANUP=300      # 5 minutes
#   SCHEDULE_DISK_MONITOR=30        # 30 seconds
#   CLEANUP_AUDIO_RETENTION_DAYS=1  # 1 day
#   CLEANUP_LOGS_RETENTION_DAYS=1   # 1 day
#   CLEANUP_DISK_THRESHOLD_PCT=90   # 90%
#   CLEANUP_EMERGENCY_CLEANUP=false
#
# Production Profile (conservative cleanup):
#   SCHEDULE_AUDIO_CLEANUP=3600     # 1 hour
#   SCHEDULE_LOG_CLEANUP=86400      # 24 hours
#   SCHEDULE_CACHE_CLEANUP=1800     # 30 minutes
#   SCHEDULE_DISK_MONITOR=300       # 5 minutes
#   CLEANUP_AUDIO_RETENTION_DAYS=7  # 7 days
#   CLEANUP_LOGS_RETENTION_DAYS=7   # 7 days
#   CLEANUP_DISK_THRESHOLD_PCT=85   # 85%
#   CLEANUP_EMERGENCY_CLEANUP=true  # Enable emergency cleanup
#
# The scheduler automatically:
#   - Removes audio files only for COMPLETE or FAILED tasks
#   - Cleans up log files older than retention period
#   - Manages Redis cache entries with TTL-based expiration
#   - Monitors disk usage and triggers cleanup on threshold
#   - Cleans up RQ job entries older than 24 hours

# ============================================================================
# Performance Tuning (Optional)
# ============================================================================
# CPU Performance (when running on CPU)
OMP_NUM_THREADS=4
# Adjust based on CPU cores: recommended = (CPU cores / 2)

# ============================================================================
# Speaker Diarization Settings (Optional)
# ============================================================================
# Speaker diarization adds speaker labels to transcripts
APP_DIARIZATION__ENABLED=false
APP_DIARIZATION__MODEL_PATH=data/models/speaker-diarization-community-1
APP_DIARIZATION__OVERLAP_THRESHOLD=0.3
APP_DIARIZATION__REQUIRE_CUDA=false

# Memory Management for Diarization (per official pyannote.audio documentation)
# These are the recommended defaults from official pyannote-audio examples
# https://github.com/pyannote/pyannote-audio/blob/main/tutorials/community/offline_usage_speaker_diarization.ipynb
# Official defaults: embedding_batch_size=32, segmentation_batch_size=32
APP_DIARIZATION__EMBEDDING_BATCH_SIZE=32
APP_DIARIZATION__SEGMENTATION_BATCH_SIZE=32

# Memory/Speed Tradeoff Guide:
#   Batch Size | Memory Usage | Speed | Use Case |
#   4          | ~0.25-0.5 GB | Slow  | Very long audio (>1 hour) or limited memory |
#   8          | ~0.5-1 GB    | Moderate | Long audio (30-60 min) |
#   16         | ~1-2 GB      | Good  | Medium audio (15-30 min) |
#   32 (default) | ~2-4 GB    | Fast  | Short audio (<15 min) - OFFICIAL DEFAULT |
#   64         | ~4-8 GB      | Faster | Very short audio (<5 min), plenty of memory |

# ============================================================================
# Notes
# ============================================================================
# 1. ChunkFormer parameters were corrected in V1.0:
#    - chunk_size: 64 frames (was incorrectly 16000 samples)
#    - total_batch_duration: 14400 seconds (was incorrectly documented as ms)
#
# 2. For Distil-Whisper models (e.g., distil-large-v3):
#    - Set WHISPER_CONDITION_ON_PREVIOUS_TEXT=false
#    - This is REQUIRED for proper accuracy
#
# 3. Language detection:
#    - Leave WHISPER_LANGUAGE empty for auto-detection
#    - Set to specific code (e.g., "en", "vi") to force language
#
# 4. GPU Memory:
#    - Adjust LLM_*_GPU_MEMORY_UTILIZATION if you get OOM errors
#    - Recommended range: 0.85-0.95
#
# 5. Security:
#    - ALWAYS change SECRET_API_KEY in production
#    - Use a strong random key (32+ characters)
