# MAIE (Modular Audio Intelligence Engine) - Production Environment Configuration
#
# This template file contains production-specific environment variables.
# Copy this file to .env.production and customize as needed.
# Do not commit your .env.production file to version control.
#
# Environment variables use APP_ prefix with __ delimiter for nested settings.
# Example: APP_LOGGING__LOG_LEVEL maps to settings.logging.log_level

# ============================================================================
# CORE CONFIGURATION
# ============================================================================

# Environment name
APP_ENVIRONMENT=production

# Enable debug mode
APP_DEBUG=false

# Enable verbose component logging
APP_VERBOSE_COMPONENTS=false

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Log level (TRACE, DEBUG, INFO, SUCCESS, WARNING, ERROR, CRITICAL)
APP_LOGGING__LOG_LEVEL=INFO

# Serialize logs to console (JSON format)
APP_LOGGING__LOG_CONSOLE_SERIALIZE=true

# Serialize logs to file (JSON format)
APP_LOGGING__LOG_FILE_SERIALIZE=true

# Log rotation size
APP_LOGGING__LOG_ROTATION=1 GB

# Log retention period
APP_LOGGING__LOG_RETENTION=30 days

# ============================================================================
# API CONFIGURATION
# ============================================================================

# API secret key (MUST CHANGE IN PRODUCTION)
APP_API__SECRET_KEY=CHANGE_ME_IN_PRODUCTION

# Maximum file upload size in MB
APP_API__MAX_FILE_SIZE_MB=500

# Default ASR backend to use when not specified in API requests
# Options: whisper, chunkformer
APP_API__DEFAULT_ASR_BACKEND=chunkformer

# ============================================================================
# REDIS CONFIGURATION
# ============================================================================

# Maximum queue depth for backpressure management
APP_REDIS__MAX_QUEUE_DEPTH=100

# ============================================================================
# FILE PATHS
# ============================================================================

# Audio directory path
APP_PATHS__AUDIO_DIR=/app/data/audio

# Models directory path
APP_PATHS__MODELS_DIR=/app/data/models

# Templates directory path
APP_PATHS__TEMPLATES_DIR=/app/templates

# ============================================================================
# WORKER CONFIGURATION
# ============================================================================

# Worker name identifier
APP_WORKER__WORKER_NAME=maie-worker-prod

# Job timeout in seconds
APP_WORKER__JOB_TIMEOUT=600

# Result retention time in seconds (24 hours)
APP_WORKER__RESULT_TTL=86400

# Worker concurrency (number of concurrent jobs)
APP_WORKER__WORKER_CONCURRENCY=2

# Worker prefetch multiplier
APP_WORKER__WORKER_PREFETCH_MULTIPLIER=4

# Worker prefetch timeout in seconds
APP_WORKER__WORKER_PREFETCH_TIMEOUT=30

# ============================================================================
# CLEANUP & MAINTENANCE
# ============================================================================

# Audio cleanup interval in seconds
APP_CLEANUP__AUDIO_CLEANUP_INTERVAL=3600

# Log cleanup interval in seconds
APP_CLEANUP__LOG_CLEANUP_INTERVAL=86400

# Cache cleanup interval in seconds
APP_CLEANUP__CACHE_CLEANUP_INTERVAL=1800

# Disk monitoring interval in seconds
APP_CLEANUP__DISK_MONITOR_INTERVAL=300

# Days to keep audio files
APP_CLEANUP__AUDIO_RETENTION_DAYS=7

# Days to keep log files
APP_CLEANUP__LOGS_RETENTION_DAYS=7

# Disk usage threshold percentage for alerts
APP_CLEANUP__DISK_THRESHOLD_PCT=85

# Enable automatic emergency cleanup on disk alerts
APP_CLEANUP__EMERGENCY_CLEANUP=true

# ============================================================================
# LLM ENHANCEMENT CONFIGURATION
# ============================================================================

# GPU memory utilization (0.1 to 1.0)
APP_LLM_ENHANCE__GPU_MEMORY_UTILIZATION=0.9

# Maximum model context length
APP_LLM_ENHANCE__MAX_MODEL_LEN=32768

# ============================================================================
# LLM SUMMARIZATION CONFIGURATION
# ============================================================================

# GPU memory utilization (0.1 to 1.0)
APP_LLM_SUM__GPU_MEMORY_UTILIZATION=0.9

# Maximum model context length
APP_LLM_SUM__MAX_MODEL_LEN=32768

# ============================================================================
# FEATURE FLAGS
# ============================================================================

# Enable enhancement feature
APP_FEATURES__ENABLE_ENHANCEMENT=true

